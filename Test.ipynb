{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from random import random\n",
    "from MST import kruskal, prim\n",
    "from DisjointSet import DisjointSet\n",
    "\n",
    "\n",
    "# os.environ['JAVA_HOME'] = '/Library/Java/JavaVirtualMachines/jdk1.8.0_172.jdk/Contents/Home'\n",
    "# os.environ['PYSPARK_PYTHON'] = '/usr/local/bin/python3.5'\n",
    "\n",
    "\n",
    "def shuffle(seq):\n",
    "    \"\"\"\n",
    "    to shuffle a sequence\n",
    "\n",
    "    :param seq: a sequence.\n",
    "    :return: a sequence after shuffling.\n",
    "    \"\"\"\n",
    "    return sorted(seq, key=lambda k: random())\n",
    "\n",
    "\n",
    "def edge_partitioning(sc, nodes, edges, num_partition=4):\n",
    "    \"\"\"\n",
    "    implementation of edge partitioning Kruskal's algorithm\n",
    "\n",
    "    :param nodes: nodes for input.\n",
    "    :param edges: edges for input.\n",
    "    :param num_partition: number of partitions.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # parallelize\n",
    "    edges = sc.parallelize(shuffle(edges), num_partition)\n",
    "\n",
    "    # define function for calculating local MSTs\n",
    "    def local_kruskal(iterator):\n",
    "        for edge in kruskal(nodes=nodes, edges=iterator):\n",
    "            yield edge\n",
    "    # calculate local MSTs\n",
    "    subtrees = edges.mapPartitions(local_kruskal).collect()\n",
    "\n",
    "    # calculate the global MST\n",
    "    return kruskal(nodes=nodes, edges=subtrees)\n",
    "\n",
    "\n",
    "def vertex_partitioning(sc, nodes, edges, num_partition=4):\n",
    "    \"\"\"\n",
    "    implementation of vertex partitioning Kruskal's algorithm\n",
    "\n",
    "    :param nodes: nodes for input.\n",
    "    :param edges: edges for input.\n",
    "    :param num_partition: number of partitions.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # define function for calculating combinations of different vertex partitions\n",
    "    def combine(iterator):\n",
    "        for i in iterator:\n",
    "            if i[0] < i[1]:\n",
    "                yield i[0] + i[1]\n",
    "    vertices = sc.parallelize(shuffle(nodes), num_partition).glom()\n",
    "    vertices = vertices.cartesian(vertices) \\\n",
    "                       .mapPartitions(combine, preservesPartitioning=False)\n",
    "\n",
    "    # parallelize\n",
    "    vertices = sc.parallelize(vertices.collect(), num_partition)\n",
    "\n",
    "    # define function for calculating local MSTs\n",
    "    def local_kruskal(iterator):\n",
    "        for subset in iterator:\n",
    "            for edge in kruskal(nodes=set(subset), edges=edges):\n",
    "                yield edge\n",
    "    # calculate local MSTs\n",
    "    subtrees = vertices.mapPartitions(local_kruskal).distinct().collect()\n",
    "\n",
    "    # calculate the global MST\n",
    "    return kruskal(nodes=nodes, edges=subtrees)\n",
    "\n",
    "\n",
    "def parallel_prim(sc, nodes, edges, num_partition=4):\n",
    "    \"\"\"\n",
    "    implementation of parallel Prim's algorithm\n",
    "\n",
    "    :param nodes: nodes for input.\n",
    "    :param edges: edges for input.\n",
    "    :param num_partition: number of partitions.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # edges of the minimum spanning tree\n",
    "    mst = []\n",
    "\n",
    "    # initialize a forest for all nodes\n",
    "    forest = DisjointSet(nodes)\n",
    "\n",
    "    # define function for generating graph\n",
    "    def generate_graph(iterator):\n",
    "          for edge in iterator:\n",
    "              for i in range(2):\n",
    "                  yield (edge[i], (edge[1-i], edge[2]))\n",
    "    # store the graph in an adjacency list\n",
    "    adjacent = sc.parallelize(edges, num_partition) \\\n",
    "                 .mapPartitions(generate_graph, preservesPartitioning=True) \\\n",
    "                 .groupByKey(numPartitions=num_partition) \\\n",
    "                 .mapValues(lambda x: sorted(x, key=lambda y: y[1])) \\\n",
    "                 .persist()\n",
    "\n",
    "    # candidate edges of the global MST\n",
    "    candidates = [None]\n",
    "    # loop until there is no candidate\n",
    "    while len(candidates) != 0:\n",
    "        # broadcast the forest to each machine\n",
    "        connection = sc.broadcast(forest)\n",
    "\n",
    "        # define function for finding minimum edges leaving each disjoint set\n",
    "        def find_minimum(iterator):\n",
    "            for group in iterator:\n",
    "                src = group[0]\n",
    "                for (dst, weight) in group[1]:\n",
    "                    if connection.value.find(src) != connection.value.find(dst):\n",
    "                        yield (src, dst, weight) if src < dst else (dst, src, weight)\n",
    "                        break\n",
    "        # obtain the list of minimum edges leaving each disjoint set\n",
    "        candidates = sorted(adjacent.mapPartitions(find_minimum).distinct().collect(), key=lambda x: x[2])\n",
    "\n",
    "        # calculate the global MST\n",
    "        for candidate in candidates:\n",
    "            # find the parents of src and dst respectively\n",
    "            if forest.unite(candidate[0], candidate[1]):\n",
    "                # add the current edge into the minimum spanning tree if it doesn't make a circuit\n",
    "                mst.append(candidate)\n",
    "\n",
    "    # return the global MST\n",
    "    return mst\n",
    "\n",
    "\n",
    "def get_nodes_edges(file):\n",
    "    nodes, edges = set(), list()\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip().split()\n",
    "            # insert nodes\n",
    "            nodes.add(line[0])\n",
    "            nodes.add(line[1])\n",
    "            # insert edges\n",
    "            edges.append((line[0], line[1], line[2] if len(line) is 3 else 1.0))\n",
    "        \n",
    "    return nodes, edges, len(nodes), len(edges)\n",
    "\n",
    "def save_result(file, lists):\n",
    "    lists = [str(line) + \"\\n\" for line in lists]\n",
    "    with open(file, \"w\") as f:\n",
    "        f.writelines(lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "conf.set('spark.executor.memory', '8g')\n",
    "sc = SparkContext(\"local\", conf=conf)\n",
    "sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_set = \"data/netscience.net\" \n",
    "# http://vlado.fmf.uni-lj.si/pub/networks/data/collab/netscience.htm\n",
    "# 1589 nodes and 2742 edges\n",
    "# Prim                      0.7 (s)\n",
    "# Kruskal                   0.1 (s)\n",
    "# Edge_partitioning         8.1 (s)\n",
    "# Vertex_partitioning       28.1 (s)\n",
    "# Parallel_prim             16.9 (s)\n",
    "\n",
    "# data_set = \"data/cora.cites\" \n",
    "# https://s3.us-east-2.amazonaws.com/dgl.ai/dataset/cora_raw.zip\n",
    "# 2708 nodes and 5429 edges \n",
    "# Prim                      2.6 (s)\n",
    "# Kruskal                   0.2 (s)\n",
    "# Edge_partitioning         8.4 (s)\n",
    "# Vertex_partitioning       28.8 (s)\n",
    "# Parallel_prim             21.1 (s)\n",
    "\n",
    "# data_set = \"data/com-dblp.ungraph.txt\" \n",
    "# http://snap.stanford.edu/data/com-DBLP.html\n",
    "# 317,080 nodes and 1,049,866 edges\n",
    "# Edge partitioning         21.0 (s)         \n",
    "# Vertex partitioning       72.1 (s)\n",
    "# Parallel prim             63.5 (s)\n",
    "\n",
    "# data_set = \"data/web-NotreDame.txt\" \n",
    "# http://snap.stanford.edu/data/web-NotreDame.html\n",
    "# 325,729 nodes and 1,497,134 edges\n",
    "# Edge partitioning          17.9 (s)         \n",
    "# Vertex partitioning        72.6 (s)\n",
    "# Parallel prim              46.1 (s)\n",
    "\n",
    "# data_set = \"data/web-Stanford.mtx\" \n",
    "# 281,903 nodes and 2,312,497 edges\n",
    "# Edge_partitioning         38.0 (s)\n",
    "# Vertex_partitioning       95.8 (s)\n",
    "# Parallel_prim             117.6 (s)   \n",
    "\n",
    "# data_set = \"data/web-Google.txt\" \n",
    "# http://snap.stanford.edu/data/web-Google.html\n",
    "# 875,713 nodes and 5,105,039 edges\n",
    "# Edge partitioning         57.9 (s)         \n",
    "# Vertex partitioning       180.9 (s)\n",
    "# Parallel prim             195.2 (s)\n",
    " \n",
    "\n",
    "# data_set = \"data/web-BerkStan.txt\" \n",
    "# http://snap.stanford.edu/data/web-BerkStan.html\n",
    "# 685,230 nodes and 7,600,595 edges\n",
    "# Edge partitioning         69.4 (s)         \n",
    "# Vertex partitioning       231.8 (s)\n",
    "# Parallel prim             334.7 (s)\n",
    "\n",
    "# data_set = \"data/roadNet-PA.txt\" \n",
    "# http://snap.stanford.edu/data/roadNet-PA.html\n",
    "# 1,088,092 nodes and 1,541,898 edges\n",
    "# Edge partitioning         62.7 (s)         \n",
    "# Vertex partitioning       185.8 (s)\n",
    "# Parallel prim             202.7 (s)\n",
    "\n",
    "data_set = \"data/as-skitter.txt\" \n",
    "# http://snap.stanford.edu/data/as-Skitter.html\n",
    "# 1,696,415nodes and  11,095,298 edges\n",
    "# Edge partitioning          (s)         \n",
    "# Vertex partitioning        (s)\n",
    "# Parallel prim              (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Convert file to nodes and edges data/as-skitter.txt\nConvert finish 12.759890079498291 (s)\n1696415 nodes and 11095298 edges\n"
    }
   ],
   "source": [
    "# Convert file to nodes and edges\n",
    "print(\"Convert file to nodes and edges %s\" % data_set)\n",
    "t0 = time.time()\n",
    "nodes, edges, num_nodes, num_edges = get_nodes_edges(data_set)\n",
    "t1 = time.time()\n",
    "print(\"Convert finish %s (s)\" % str(t1 - t0))\n",
    "print(\"%s nodes and %s edges\" % (str(num_nodes), str(num_edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge partitioning\n",
    "t6 = time.time()\n",
    "edge_partitioning_result = edge_partitioning(sc, nodes, edges, num_partition=4)\n",
    "t7 = time.time()\n",
    "print(\"Edge_partitioning %s (s)\" % str(t7 - t6))\n",
    "print(\"%s edges\" % len(edge_partitioning_result))\n",
    "save_result(\"result/edge_partitioning_result.txt\", edge_partitioning_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prim\n",
    "# t2 = time.time()\n",
    "# prim_result = prim(nodes, edges, 5)\n",
    "# t3 = time.time()\n",
    "# print(\"Prim %s (s)\" % str(t3 - t2))\n",
    "# print(\"%s edges\" % len(prim_result))\n",
    "# save_result(\"result/prim_result.txt\", prim_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kruskal\n",
    "# t4 = time.time()\n",
    "# kruskal_result = kruskal(nodes, edges)\n",
    "# t5 = time.time()\n",
    "# print(\"Kruskal %s (s)\" % str(t5 - t4))\n",
    "# print(\"%s edges\" % len(kruskal_result))\n",
    "# save_result(\"result/kruskal_result.txt\", kruskal_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Vertex_partitioning 69.74839329719543 (s)\n317079 edges\n"
    }
   ],
   "source": [
    "# Vertex partitioning\n",
    "t8 = time.time()\n",
    "vertex_partitioning_result = vertex_partitioning(sc, nodes, edges, num_partition=4)\n",
    "t9 = time.time()\n",
    "print(\"Vertex_partitioning %s (s)\" % str(t9 - t8))\n",
    "print(\"%s edges\" % len(vertex_partitioning_result))\n",
    "save_result(\"result/vertex_partitioning_result.txt\", vertex_partitioning_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel prim\n",
    "t10 = time.time()\n",
    "parallel_prim_result = parallel_prim(sc, nodes, edges, num_partition=4)\n",
    "t11 = time.time()\n",
    "print(\"Parallel_prim %s (s)\" % str(t11 - t10))\n",
    "print(\"%s edges\" % len(parallel_prim_result))\n",
    "save_result(\"result/parallel_prim_result.txt\", parallel_prim_result)"
   ]
  }
 ]
}